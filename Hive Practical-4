# How many ways are there to insert data into table

1. inserts commands (these run mapreduce and takes lot of time. This is not efficient way)
2. loading the data from files ( this is the most preferred or industry ready way).

load the data from  local file system
load the data from hdfs
3. load data from one table to another

# Downloading the products.csv file into home/clouder folder

[cloudera@quickstart ~]$ ls
cloudera-manager  eclipse                     myscript.hql~  --table
cm_api.py         enterprise-deployment.json  orders.java    --targer
--connect         express-deployment.json     parcels        Templates
Desktop           kerberos                    --password     --username
dir1              lib                         Pictures       Videos
Documents         Music                       products.csv   workspace
Downloads         myscript.hql                Public

[cloudera@quickstart ~]$ pwd
/home/cloudera

[cloudera@quickstart ~]$ ls
cloudera-manager  eclipse                     myscript.hql~  --table
cm_api.py         enterprise-deployment.json  orders.java    --targer
--connect         express-deployment.json     parcels        Templates
Desktop           kerberos                    --password     --username
dir1              lib                         Pictures       Videos
Documents         Music                       products.csv   workspace
Downloads         myscript.hql                Public
[cloudera@quickstart ~]$ ls -ltr

total 224
-rwxrwxr-x  1 cloudera cloudera  4228 Oct 23  2017 parcels
drwxrwxr-x  2 cloudera cloudera  4096 Oct 23  2017 lib
-rwxrwxr-x  1 cloudera cloudera  5007 Oct 23  2017 kerberos
-rw-rw-r--  1 cloudera cloudera 50515 Oct 23  2017 express-deployment.json
-rw-rw-r--  1 cloudera cloudera 53655 Oct 23  2017 enterprise-deployment.json
drwxrwxr-x  4 cloudera cloudera  4096 Oct 23  2017 Documents
-rwxrwxr-x  1 cloudera cloudera  9964 Oct 23  2017 cm_api.py
-rwxrwxr-x  1 cloudera cloudera  5387 Oct 23  2017 cloudera-manager
drwxr-xr-x  2 cloudera cloudera  4096 Sep  6 11:06 Videos
drwxr-xr-x  2 cloudera cloudera  4096 Sep  6 11:06 Templates
drwxr-xr-x  2 cloudera cloudera  4096 Sep  6 11:06 Public
drwxr-xr-x  2 cloudera cloudera  4096 Sep  6 11:06 Pictures
drwxr-xr-x  2 cloudera cloudera  4096 Sep  6 11:06 Music
drwxrwxr-x  2 cloudera cloudera  4096 Sep  8 23:39 dir1
drwxrwsr-x  9 cloudera cloudera  4096 Sep 16 06:03 eclipse
drwxrwxr-x  6 cloudera cloudera  4096 Sep 16 07:48 workspace
-rw-rw-r--  1 cloudera cloudera     0 Sep 19 11:45 --connect
-rw-rw-r--  1 cloudera cloudera     0 Sep 19 20:08 --username
-rw-rw-r--  1 cloudera cloudera     0 Sep 19 20:08 --table
-rw-rw-r--  1 cloudera cloudera     0 Sep 19 20:08 --password
-rw-rw-r--  1 cloudera cloudera   149 Sep 19 20:08 --targer
-rw-rw-r--  1 cloudera cloudera 16344 Sep 19 20:21 orders.java
-rw-rw-r--  1 cloudera cloudera    58 Sep 29 23:11 myscript.hql~
-rw-rw-r--  1 cloudera cloudera    58 Sep 29 23:11 myscript.hql
-rwxrwxrwx  1 cloudera cloudera   123 Sep 30 20:35 products.csv
drwxr-xr-x  2 cloudera cloudera  4096 Sep 30 20:53 Downloads
drwxrwxr-x 10 cloudera cloudera  4096 Oct  1 00:11 Desktop

#Copying File products.csv from local to hdfs file system

[cloudera@quickstart ~]$ hadoop fs -copyFromLocal /home/cloudera/Downloads/products.csv /data

# Seeing the data in products.csv
[cloudera@quickstart ~]$ cat products.csv
iphone7, iPhone 7, 950
camera_canon, Canon 570x, 1000
washingmachine_samsung, Samsung Swift, 400
tv_vu, Vu 56 Inch, 600

# Creating a Table products_managed

hive> create table products_managed(
    > id string,
    > title string,
    > cost float
    > )row format delimited fields terminated by ',' stored as textfile;
OK
Time taken: 0.812 seconds

hive> show tables;
OK
customers
orders
products_managed
Time taken: 0.425 seconds, Fetched: 3 row(s)


# Load data local inpath '/home/cloudera/products.csv' into table products_managed

load data local inpath '/home/cloudera/products.csv' into table products_managed;
The table we created is a managed table
We have not specified the path of data. That means data will be kept in default path (/user/hive/warehouse)


hive> load data local inpath '/home/cloudera/products.csv' into table products_managed;
Loading data to table trendytech.products_managed
Table trendytech.products_managed stats: [numFiles=1, totalSize=123]
OK
Time taken: 1.688 seconds


hive> select * from products_managed;
OK
iphone7	 iPhone 7	950.0
camera_canon	 Canon 570x	1000.0
washingmachine_samsung	 Samsung Swift	400.0
tv_vu	 Vu 56 Inch	600.0
 	NULL	NULL
	NULL	NULL
Time taken: 0.124 seconds, Fetched: 6 row(s)

hive> dfs -ls /user/hive/warehouse/trendytech.db;
Found 3 items
drwxrwxrwx   - cloudera supergroup          0 2022-09-28 11:25 /user/hive/warehouse/trendytech.db/customers
drwxrwxrwx   - cloudera supergroup          0 2022-09-29 21:17 /user/hive/warehouse/trendytech.db/orders
drwxrwxrwx   - cloudera supergroup          0 2022-10-01 00:38 /user/hive/warehouse/trendytech.db/products_managed


hive> dfs -ls /user/hive/warehouse/trendytech.db/products_managed;
Found 1 items
-rwxrwxrwx   1 cloudera supergroup        123 2022-10-01 00:38 /user/hive/warehouse/trendytech.db/products_managed/products.csv

# so on loading from local, product.csv is copied from local to hdfs (/user/hive/warehouse) 
copy paste

# to load the data from hdfs folder to hive table.
# we should have the folder created in hdfs.


[cloudera@quickstart ~]$ hadoop fs -ls /
Found 8 items
drwxrwxrwx   - hdfs     supergroup          0 2017-10-23 09:15 /benchmarks
-rw-r--r--   1 cloudera supergroup        123 2022-10-01 00:20 /data
drwxr-xr-x   - hbase    supergroup          0 2022-09-09 06:43 /hbase
drwxr-xr-x   - cloudera supergroup          0 2022-09-19 20:25 /queryresult
drwxr-xr-x   - solr     solr                0 2017-10-23 09:18 /solr
drwxrwxrwt   - hdfs     supergroup          0 2022-09-06 11:09 /tmp
drwxr-xr-x   - hdfs     supergroup          0 2022-09-18 03:21 /user
drwxr-xr-x   - hdfs     supergroup          0 2017-10-23 09:17 /var

# Removing he /data directory
[cloudera@quickstart ~]$ hadoop fs -rm -r /data
Deleted /data

# creating new directory by name /data
[cloudera@quickstart ~]$ hadoop fs -mkdir /data

#copying file products.csv from local to hdfs
[cloudera@quickstart ~]$ hadoop fs -put products.csv /data


[cloudera@quickstart ~]$ hadoop fs -ls /data
Found 1 items
-rw-r--r--   1 cloudera supergroup        123 2022-10-01 00:54 /data/products.csv

# Loading data from HDFS to into table products_managed
load data inpath '/data/products.csv' into table products_managed;


hive> load data inpath '/data/products.csv' into table products_managed;
Loading data to table trendytech.products_managed
Table trendytech.products_managed stats: [numFiles=2, totalSize=246]
OK
Time taken: 0.519 seconds

# In this case when we load from HDFS file 
it will be cut paste of data 
that means you wont be able to see the products.csv in /data folder in hdfs

/user/hive/warehouse




